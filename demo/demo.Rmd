---
title: "ConsensusVelo"
author: "Huizi Zhang"
date: "2024-06-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
```

# Example - Fit a single gene

```{r}
library(ggplot2)
library(pheatmap)
library(coda)
library(ConsensusVelo)
```

The simulated data for fitting a single gene can be obtained from 

```{r}
# sim.data contains the generated observations for a single gene
data("sim.data")
u.obs <- sim.data$u.obs; s.obs <- sim.data$s.obs
```

To obtain empirical estimates,

```{r}
# get empirical estimates for parameters from the data
empirical <- get_empirical(u.obs = u.obs, s.obs = s.obs, u.quant = c(0.35,0.8), s.quant = c(0.35,0.8), alpha='max')
```

Before running consensus velocity algorithm, we need to prepare different initial values for the state to initialize each chain. This can be done by the following.

```{r}
# generate multiple initial values for state k
# first type (based on the distance to the centre points of two states)
# second type (based on the distance to the closest points of two states)
set.seed(43)
k.inits <- replicate(50, {
  if(runif(1) > 0.5){
    c(generate_k(u.obs = u.obs, s.obs = s.obs, empirical = empirical, n_inits = 1, type = 'centre', plot=FALSE))
  }else{
    c(generate_k(u.obs = u.obs, s.obs = s.obs, empirical = empirical, n_inits = 1, type = 'min', plot=FALSE))
  }
})
```

## Consensus velocity

Now to run consensus velocity,

```{r}
# consensus velocity (in parallel)
# number of chains
Width <- 50
# number of iterations
Depth <- 5000

# define other prior parameters, if not provided, default values will be used
## standard deviations of alpha1, gamma and switching point
empirical$params$alpha1.sd=5
empirical$params$gamma.sd=0.4
empirical$params$t0.sd=3
## upper and lower bound of lambda
empirical$params$lambda.lower=0; empirical$params$lambda.upper=5
## the parameter in the inverse-gamma prior for two variance parameters: IG(invgamma.f, invgamma.f * empirical)
empirical$params$invgamma.f=1
## the parameter in the prior for mu_tau (also for var_tau), control the variance: TruncN(mean, (hyper.f*mean)^2)
empirical$params$hyper.f=2

# mcmc setup, if not provided, the following default values will be used:
# df <- empirical$params
# alpha1.sd <- df$alpha1.hat/6; gamma.sd <- df$gamma.hat/6; t0.sd <- df$t0.hat/3; 
# lambda.lower <- 0; lambda.upper <- 5; invgamma.f <- 1; hyper.f <- 2
mcmc_list <- list(prep_niter = 3000, prep_burn_in = 2000, prep_thinning = 1,
                  comp_niter = Depth, comp_burn_in = 0, comp_thinning = 1)

set.seed(1)
consensus_result <- velo_consens(u.obs = u.obs, s.obs = s.obs, state_inits = k.inits, empirical = empirical,
                                 mcmc = mcmc_list, epsilon = 1e-3, n_cores = 5, n_chains = Width)
```

To select a suitable value for $W$ and $D$ (number of chains and number of iterations), we compute entropy and moving average of log-posterior density,

```{r}
# get posterior samples for k and log-posterior
k_lp_result <- lapply(consensus_result, function(l) {
  return(list(k=l$k_output,lp=l$log_post))
})
# a list, each corresponding to the samples of k from a single chain
mcmc_k_result <- lapply(k_lp_result,function(l) l$k)
# a matrix: n_chains * n_iterations
mcmc_lp_result <- t(sapply(k_lp_result,function(l) l$lp))
rm(k_lp_result)

# candidate values for W
Ws <- 1:50

# plot absolute difference in entropy, conditional on a fixed D (or several Ds).
plot_entropy(Ws = Ws, Ds = 5000, mcmc_k = mcmc_k_result)

# candidate values for D
Ds <- c(1, seq(500,5000,by=500))

# plot absolute difference in moving average of log-posterior, conditional on a fixed W (or several Ws).
plot_lp(Ws = 50, Ds = Ds, mcmc_lp = mcmc_lp_result)


# suppose we decide to use all the chains and the last 100 iterations of each chain
# below we clean up the results

# the final output of the function below is a list of length = no. of chains. Within each list,
# there are matrices for univariate parameters ('params'),
# for 'tau', 'mus', 'v', 't', 'k', 'hyper'
# the rows for of every matrix correspond to samples, with nrow = length(ind)
combined <- result_combine(consensus_result = consensus_result, Width = 50, ind = 4901:5000)

```

After collecting MCMC samples based on selected $W$ and $D$, we can check the fitted phase portrait, calculate posterior probability of belonging to the induction state for every cell, and predicted velocity.

```{r}
# to show fitted phase portrait (with some thinning)
plot_fit(combined_result = combined, u.obs = u.obs, s.obs = s.obs, thinning = 10, title = 'Example', cex = 1)

# to compute posterior probability of induction for every cell
combined_result_k <- do.call(rbind, lapply(combined, function(l) l$k))
p_ind <- apply(combined_result_k,2,function(x) mean(x==1))

# plot the probability in phase portrait
ggplot()+
  geom_point(aes(x=s.obs,y=u.obs,col=p_ind))+
  labs(x='s',y='u')+
  scale_color_gradient2(midpoint=0.5, low="blue", mid="yellow",
                        high="red", space ="Lab", name='p (induction)')+
  theme_bw()+theme(legend.position='bottom')


# to show predicted velocity for a subset of the cells
plot_predicted_velocity(combined_result = combined, u.obs = u.obs, s.obs = s.obs, delta = 1,
                        obs_ind = c(1,10,15,20,25,30,35,40,80,100,105,115,120),
                        thinning = 10, cex = 0.2, transparency = 0.5)

```

The joint posterior distribution can also be examined between pairwise parameters.

```{r}
# to check the joint posterior distribution between parameters and their correlation
# below we plot 2d density plots for selected parameters
# the parameter names can be one of the following
# 'alpha1_1','gamma','lambda','t0','u01','sigma_u_2','sigma_s_2','p'
# 't[1]', 't[2]', .....
# 'tau[1]','tau[2]', .....
# 'v[1]', 'v[2]', ....
plot_distribution_2d(combined_result = combined, param1 = 't0', param2 = 'gamma')
plot_distribution_2d(combined_result = combined, param1 = 't0', param2 = 't[100]')
```

## Posterior predictive checks

We preform posterior predictive checks by generating replicated datasets and compare them to the observed data to see
if there is any obvious discrepancy. Specifically, we generate a single dataset to compare the observed counts, and then multiple replicates to compare key statistics. We also compute posterior predictive p-values using mixed predictive distribution, for each state, which is conditional on observations with a large posterior probability of belonging to the state.

```{r}
# --- a single replicate ---
# compare generated observations
set.seed(4)
ppc_single(u.obs = u.obs, s.obs = s.obs, combined_result = combined)

# --- multiple replicates -----
# compare empirical gamma and quantiles
set.seed(4)
ppc_multiple(u.obs = u.obs, s.obs = s.obs, combined_result = combined, n_replicate = 200, prob = 0.95,
             quantiles = seq(0.05,0.95,by=0.05), u.quant = c(0.35,0.8), s.quant = c(0.35,0.8), 
             gamma.hat.obs = empirical$params$gamma.hat)

# the function plots histograms for ppp values and also outputs them, using mixed predictive distribution
set.seed(134)
ppp_values <- ppp_mixed(u.obs = u.obs, s.obs = s.obs, combined_result = combined, n_replicate = 200, prob = 0.9)

```

# Example - A post-processing step to infer a gene-shared latent time

After fitting each gene, we can implement a post-processing step to estimate a gene-shared latent time, using posterior
summaries from individual gene fit.

```{r}
# we show an example on 26 genes with 400 cells. The data is stored in a cell-by-gene matrix
data("post.summary")
u.obs <- post.summary$u.obs; s.obs <- post.summary$s.obs
# the posterior summaries for simulated data are saved as:
# x - a cell-by-gene matrix. Each entry is the posterior mean of log gene-specific latent time, conditional on the state with a larger posterior probability (stored in k.mode).
# k.mode - a cell-by-gene matrix. Each entry is the state (induction: 1, repression: 2) with a larger posterior probability.
# var.logt - an array [cell, gene, state] of posterior variance of log gene-specific latent time, for each state.
# p.hat - an array [cell, gene, state] of posterior probability of belonging to each state for each cell in each gene.
x <- post.summary$x; k.mode <- post.summary$k.mode
var.logt <- post.summary$var.logt; p.hat <- post.summary$p.hat

# below is the code to obtain these summaries for a single gene
# # posterior samples for k and t can be obtained via
# combined_result_t <- do.call(rbind, lapply(combined, function(l) l$t))
# combined_result_k <- do.call(rbind, lapply(combined, function(l) l$k))
# 
# # number of cells and number of total MCMC samples
# n <- ncol(combined_result_t); N <- nrow(combined_result_t)
# 
# # get posterior summaries
# mean.logt = array(NA,dim=c(n,2))
# var.logt = array(NA,dim=c(n,2))
# k.samples = array(NA,dim=c(n,N))
# p.hat = array(NA,dim=c(n,2))
# 
# # posterior probability of each state
# p.hat[,1] <- apply(combined_result_k,2,function(x) mean(x==1))
# p.hat[,2] <- apply(combined_result_k,2,function(x) mean(x==2))
# 
# # conditional mean and variance for log(t)
# for(k in 1:2){
#   mean.logt[,k] <- sapply(1:n,function(cc) {
# 
#     mean(log(combined_result_t[combined_result_k[,cc]==k,cc]))
# 
#   })
# 
#   var.logt[,k] <- sapply(1:n,function(cc) {
# 
#     var(log(combined_result_t[combined_result_k[,cc]==k,cc]))
# 
#   })
# }
# x <- ifelse(p.hat[,1]>0.5, mean.logt[,1], mean.logt[,2])
# k.mode <- ifelse(p.hat[,1]>0.5, 1, 2)
```

The model can be fitted through the following:

```{r}
# the post-processing step is implemented using rjags
# the output is a list of length = n_chains, within each list is a matrix
# the row corresponds to each iteration, columns correspond to variables (mu_c, sigma_2_c, rho_c, b=-log(beta))
post_result <- mcmc_shared_time(x = x, k.mode = k.mode, var.logt = var.logt, p.hat = p.hat, n_chains = 2,
                                niter = 5000, burn_in = 4000, thinning = 1)

```

Convergence of the chains can be checked by 

```{r}
par(mfrow=c(4,2))
plot(post_result, ask=T)
```

The posterior samples of gene-shared latent time are obtained by

```{r}
# to obtain posterior samples for shared time
shared_time_samples <- get_shared_time(post_result = post_result, n = 400, G = 26)
# traceplots
plot(shared_time_samples, ask=T)
```

To compute the posterior probability of one cell before another:

```{r}
# compute posterior probability of each cell having a smaller latent time than another cell and order them
# by posterior median
p_order <- order_probability(shared_time_samples = shared_time_samples)

# visualize the probabilities
my_palette <- colorRampPalette(c("blue", 'yellow','red'))(n = 400)
pheatmap(p_order,scale = "none",fontsize = 14,show_rownames = F,show_colnames = F,
         color = my_palette,border_color=NA,cluster_rows = FALSE, cluster_cols = FALSE,na_col = 'white')

```

We can visualize a point estimate of gene-shared latent time on the PCA space, or for a single gene:

```{r}
# visualize posterior median of shared time (normalized on [0,1]) on PCA space
shared_time_median <- summary(shared_time_samples)$quantiles[,3]
shared_time_pca(u.obs = u.obs, s.obs = s.obs, shared_time = shared_time_median)

# visualize posterior median of shared time for a specific gene in the phase portrait
g=1
ggplot(data = data.frame(u=u.obs[,g],s=s.obs[,g],t=shared_time_median))+
  geom_point(aes(x=s,y=u,col=t))+
  theme_bw()+
  labs(title=paste0("Gene-shared latent time"))+
  scale_color_viridis_c()+
  theme(legend.position = 'right')

```

Finally, we apply a point estimate for $1/\beta$ to adjust all the parameters and compute the predicted velocities across genes. This can be visualized on a PCA space through:

```{r}
# combined_all_genes - a list of results for all genes. Each item is the output from the function result_combine()
# if there is information for cell types, providing it to argument 'groups' will color the cells
velocity_pca(combined_all_genes = combined_all_genes, post_result = post_result,
             u.obs = u.obs, s.obs = s.obs, n_cores=2,
             obs_ind = seq(40,400,by=40), thinning = 1, cex = 0.2)
```


